---
title: 【NLP】03-微调RoBERTa模型实现中医问题答案抽取
author: Autumn
date: 2025-03-15 +0800
categories: [NLP]
tags: [NLP]
---

## 项目简介
使用roberta-base-chinese-extractive-qa模型微调中医问题语料，实现答案抽取。
项目地址：[nlp03](https://github.com/AuTuMnnn458/NLP_project/tree/main/nlp01)

### 模型
roberta-base-chinese-extractive-qa
- 地址：[roberta-base-chinese-extractive-qa(hugging face)](https://huggingface.co/uer/roberta-base-chinese-extractive-qa)
- 简介：BERT的优化版本RoBERTa，使用中文语料进行问答训练。

### 数据
train.json标注数据源来自中医药领域文本，包括【黄帝内经翻译版】、【名医百科中医篇】、【中成药用药卷】、【慢性病养生保健科普知识】四个主要来源，共标注 18478对（问题、文档、答案），来源于3500篇语料，每篇文档由人工标注产生1～4对(问题, 答案)对。

以Json格式提供，包括：
- id: 段落id
- text: 段落文本
- annotations: 包含（问题、答案）对，共有
 - Q：问题
 - A：答案


## 项目特点/难点
1. 数据的预处理是比较繁琐和困难的，QA的模型不仅需要提供序列信息，还需要提供抽取答案的具体位置，所以需要自己构造对应的数据。
2. 模型很大，训练跑起来非常慢。4060跑一个epoch需要12分钟。
3. 局限性比较大，限制在语料里提问，无法轻松实现开放域QA，这个项目更像是类似于抽取式摘要的实现。

